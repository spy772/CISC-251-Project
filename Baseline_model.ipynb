{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88b8c38",
   "metadata": {},
   "source": [
    "## Baseline Model: Logistic Resgression\n",
    "\n",
    "Since the features in the dataset are mostly numeric and after a small amount of preprosessing the data is clean and well structured, a Logistic Regression as our baseline is the most compelling model, as it is easily interpretable, and tends to preform well with numeric tablular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a95b6f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [0 1]\n",
      "Intercept: [-2.85870261]\n",
      "Coefficients: [[-0.00927033 -0.42024756  2.09670562 -0.05433176 -0.46544451 -0.03920628\n",
      "   1.92563693  0.07687589 -3.86375553  0.10608246]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"cs-training.csv\")\n",
    "\n",
    "# Clean data\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Separate features and target\n",
    "x = data.drop(columns=[\"SeriousDlqin2yrs\"])\n",
    "y = data[\"SeriousDlqin2yrs\"]\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "x_imputed = imputer.fit_transform(x)\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x_imputed)\n",
    "\n",
    "# Intialize/fit the model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(x_scaled, y)\n",
    "\n",
    "# Step 4: Print learned parameters\n",
    "print(\"Classes:\", logreg.classes_)\n",
    "print(\"Intercept:\", logreg.intercept_)\n",
    "print(\"Coefficients:\", logreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2422371",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "The most appropriate evaluation metrics for the classification task are: AUC, F1-score and Recall.\n",
    "Recall and F1-score are appropriate preformance metrics for our model because they provide a more realistic view than accuracy alone, since our data has a heavy imbalance towards False or 0 values. AUC is also an appropriate metric because it is able to measure how well the model is distinguishing between the two classes across all thresholds, and it stays reliable with imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bfd1c",
   "metadata": {},
   "source": [
    "## Train-Valiation Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca436505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset: 150000 \n",
      "train_data 120000 \n",
      "validation_data 30000\n",
      "Validation Performance Metrics:\n",
      "Recall   : 0.670\n",
      "F1-score : 0.286\n",
      "ROC AUC  : 0.802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_imputed, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\n",
    "    'original dataset:', len(data),\n",
    "    '\\ntrain_data', len(x_train),\n",
    "    '\\nvalidation_data', len(x_val)\n",
    ")\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "logreg.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred = logreg.predict(x_val_scaled)\n",
    "y_proba = logreg.predict_proba(x_val_scaled)[:, 1]\n",
    "\n",
    "recall = recall_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "auc = roc_auc_score(y_val, y_proba)\n",
    "\n",
    "print(\"Validation Performance Metrics:\")\n",
    "print(f\"Recall   : {recall:.3f}\")\n",
    "print(f\"F1-score : {f1:.3f}\")\n",
    "print(f\"ROC AUC  : {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30876ca7",
   "metadata": {},
   "source": [
    "## Baseline Interpretations\n",
    "\n",
    "- AUC = 0.80 means that the logistic regression baseline is moderately successful at seperating the two classes\n",
    "- Recall = 0.670 means the model is good at identifying most of the True or 1 values, However,\n",
    "- F1-score = 0.286 also suggests the model produces many false positives as the model struggles to balance precision and recall\n",
    "\n",
    "From this information and the understanding that logisitic regression is a simple, linear model, it can be observed that our baseline has high bias and low variance. The high bias and low variance in our baseline indicates the model is underfitting the data. However, since its AUC value is not extremely low, The model is believed to be only slightly underfitting as it is still able to generalize well to unseen data.    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
