{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a7355db",
   "metadata": {},
   "source": [
    "# Deliverable 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f373a",
   "metadata": {},
   "source": [
    "### Section 1: Full Pipeline Construction (Preprocessing + Model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399203bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison: \n",
      "\n",
      "Logistic Regression Results:\n",
      "  recall  : 0.738 ± 0.012\n",
      "  f1      : 0.295 ± 0.005\n",
      "  roc_auc : 0.831 ± 0.005\n",
      "Random Forest Results:\n",
      "  recall  : 0.146 ± 0.007\n",
      "  f1      : 0.229 ± 0.010\n",
      "  roc_auc : 0.838 ± 0.003\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, recall_score, f1_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Custom class so that we can use it in the pipeline\n",
    "class Outlier_Capper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols_to_cap_indices):\n",
    "        self.cols_to_cap_indices = cols_to_cap_indices\n",
    "        self.upper_fences = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col_idx in self.cols_to_cap_indices:\n",
    "            column_data = X[:, col_idx]\n",
    "            Q1 = np.percentile(column_data, 25)\n",
    "            Q3 = np.percentile(column_data, 75)\n",
    "            IQR = Q3 - Q1\n",
    "            self.upper_fences[col_idx] = Q3 + 1.5 * IQR\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col_idx, fence in self.upper_fences.items():\n",
    "            X_copy[:, col_idx] = np.where(X_copy[:, col_idx] > fence, fence, X_copy[:, col_idx])\n",
    "        return X_copy\n",
    "\n",
    "# Load and clean dataset\n",
    "data = pd.read_csv(\"./datasets/cs-training.csv\")\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Combine similar columns to avoid multicollinearity as discovered in deliverable 2\n",
    "data['Total_Times_Past_Due'] = (\n",
    "    data['NumberOfTime30-59DaysPastDueNotWorse'] +\n",
    "    data['NumberOfTime60-89DaysPastDueNotWorse'] +\n",
    "    data['NumberOfTimes90DaysLate']\n",
    ")\n",
    "data = data.drop(columns=[\n",
    "    'NumberOfTime30-59DaysPastDueNotWorse',\n",
    "    'NumberOfTime60-89DaysPastDueNotWorse',\n",
    "    'NumberOfTimes90DaysLate'\n",
    "])\n",
    "\n",
    "X = data.drop(columns=[\"SeriousDlqin2yrs\"])\n",
    "y = data[\"SeriousDlqin2yrs\"]\n",
    "\n",
    "\n",
    "# Pipelines\n",
    "\n",
    "outlier_indices_to_cap = [0, 2, 3] # RevolvingUtilization, DebtRatio, MonthlyIncome \n",
    "log_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('capper', Outlier_Capper(cols_to_cap_indices=outlier_indices_to_cap)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('capper', Outlier_Capper(cols_to_cap_indices=outlier_indices_to_cap)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier(n_estimators=200, max_depth=None, random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "\n",
    "# Comparison metrics \n",
    "scoring = {\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Model Comparison: \\n\")\n",
    "print(\"Logistic Regression Results:\")\n",
    "log_cv_results = cross_validate(\n",
    "    log_pipeline, \n",
    "    X.to_numpy(), \n",
    "    y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "for metric in scoring.keys():\n",
    "    mean = np.mean(log_cv_results[f'test_{metric}'])\n",
    "    std = np.std(log_cv_results[f'test_{metric}'])\n",
    "    print(f\"  {metric:8}: {mean:.3f} ± {std:.3f}\")\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "rf_cv_results = cross_validate(\n",
    "    rf_pipeline, \n",
    "    X.to_numpy(), \n",
    "    y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "# Print results\n",
    "for metric in scoring.keys():\n",
    "    mean = np.mean(rf_cv_results[f'test_{metric}'])\n",
    "    std = np.std(rf_cv_results[f'test_{metric}'])\n",
    "    print(f\"  {metric:8}: {mean:.3f} ± {std:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac58108f",
   "metadata": {},
   "source": [
    "## Analysis of Results\n",
    "\n",
    "**Recall:**\n",
    "The logistic regression model boasts a far higher recall score of 0.73 versus the random forest model's 0.14. This means that the logistic regression model would be able to more successfully predict if someone will experience financial distress in the next two years. This is a very important metric to the bank. If they give loans to people who won't be able to pay them back they risk great financial loss.\n",
    "\n",
    "**F1-Score:**\n",
    "The F1-scores for both models are similar but the logistic regression model pulls ahead slightly at 0.295 versus random forest model's 0.229. This means the logistic regression model achieves a better balance between precision and recall compared to the random forest model.\n",
    "\n",
    "**ROC AUC:**\n",
    "The random forest model is superior in this metric with a score of 0.838 versus the logistic regression model's 0.831. This means the random forest model is better at discriminating between people who are risky to loan to and people who are not. This is probably because the random forest model is more conservative when classifying risky people to loan to as seen by its low recall score. However given the difference is so small it is not very significant.\n",
    "\n",
    "Based on these results the logistic regression model seems like a clear winner due to its superiority in Recall and F1-Score as well as its comparable ROC AUC score.\n",
    "\n",
    "\n",
    "### Design Choice Justification\n",
    "\n",
    "We decided to just use a pipeline and not a column transformer as it is not necessary for our dataset. This is because we only have numerical columns,  just using the pipeline works well and is a simpler solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483b145",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
